{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe following experiment follows the below architecture, in order:\\n\\ninput\\nlayer 1: convolution\\nlayer 2: pooling\\nlayer 3: convolution\\nlayer 4: pooling\\nlayer 5: convolution\\nlayer 6: fully connected\\nlayer 7: fully connected\\noutput\\n\\n\\nFollowing the cnn, we use a classification technique:\\n\\nSupport Vector Machine\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "The following experiment follows the below architecture, in order:\n",
    "\n",
    "Image Preprocessing: Face detection and cropping\n",
    "rgb -> gray\n",
    "face resize to 32x32\n",
    "\n",
    "|\n",
    "v\n",
    "\n",
    "Feature extraction: Create Face Embeddings\n",
    "input\n",
    "layer 1: convolution\n",
    "layer 2: pooling\n",
    "layer 3: convolution\n",
    "layer 4: pooling\n",
    "layer 5: convolution\n",
    "layer 6: fully connected\n",
    "layer 7: fully connected\n",
    "output\n",
    "\n",
    "|\n",
    "v\n",
    "\n",
    "Classification: Perform Face Classification\n",
    "(experiment_1a)-> Logistic Regression\n",
    "(experiment_2a)-> Support Vector Machine\n",
    "(experiment_3a)-> Euclidean Distance Nearest Neighbors\n",
    "\n",
    "Following the cnn, we use a classification technique:\n",
    "\n",
    "Support Vector Machine\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/josephwoodall/ds_personal_projects/brooks_family_photo_project/brooks_family_photo_original_dataset/jpeg' # path to jpeg dataset \n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/josephwoodall/ds_personal_projects/brooks_family_photo_project/brooks_family_photo_original_dataset/jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-307702f5a90d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# enumerate over the files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;31m# path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/josephwoodall/ds_personal_projects/brooks_family_photo_project/brooks_family_photo_original_dataset/jpeg'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Image Preprocessing: Face detection and cropping\n",
    "rgb -> gray\n",
    "face resize to 32x32\n",
    "create face embeddings\n",
    "\n",
    "'''\n",
    "\n",
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size = (32, 32)):\n",
    "    # loading the image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to rgb if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    pixels = asarray(image)\n",
    "    # create the detector, using default weights\n",
    "    detector = MTCNN()\n",
    "    # detect faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "\n",
    "    # extract the bounding box from the first face\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    # bug fix \n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "\n",
    "    # extracting the face\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "\n",
    "    # reszing pixels to the model size \n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize()\n",
    "    face_array = asarray(image)\n",
    "    return face_array\n",
    "\n",
    "# load images and extract faces for all images in a directory\n",
    "def load_faces(directory):\n",
    "    faces = list()\n",
    "    # enumerate flies\n",
    "    for filename in listdir(directory):\n",
    "        path = directory + filename\n",
    "        # get face\n",
    "        face = extract_face(path)\n",
    "        # store \n",
    "        faces.append(face)\n",
    "    return faces\n",
    "\n",
    "# load a dataset that contains one subdir for each class that in turn contains images\n",
    "def load_dataset(directory):\n",
    "    X, y = list(), list()\n",
    "    # enumerate folders, on per class\n",
    "    for subdir in listdir(directory):\n",
    "        # path \n",
    "        path = directory + subdir + '/'\n",
    "        # skip any files that might be in the dir\n",
    "        if not isdir(path):\n",
    "            continue\n",
    "        # load all faces in subdirectory\n",
    "        faces = load_faces(path)\n",
    "        # create labels\n",
    "        labels = [subdir for _ in range(len(faces))]\n",
    "        # summarize progress\n",
    "        print('>load %d examples for class: %s' %(len(faces), subdir))\n",
    "        # store\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "    return asarray(X), asarray(y)\n",
    "\n",
    "\n",
    "# load train dataset\n",
    "trainX, trainy = load_dataset('path/to/train/set')\n",
    "print(trainX.shape, trainy.shape)\n",
    "# load test dataset\n",
    "testX, testy = load_dataset('path/to/val/set')\n",
    "# save arrays to one file in compressed format\n",
    "savez_compressed('path/to/compressed_set.npz', trainX, trainy, testX, testy)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Feature extraction:\n",
    "input\n",
    "layer 1: convolution\n",
    "layer 2: pooling\n",
    "layer 3: convolution\n",
    "layer 4: pooling\n",
    "layer 5: convolution\n",
    "layer 6: fully connected\n",
    "layer 7: fully connected\n",
    "output\n",
    "\n",
    "'''\n",
    "# Layer 1\n",
    "model.add(Conv2D(32, (3,3), padding = 'same', input_shape = x_train.shape[1:]))\n",
    "# Layer 2\n",
    "# Layer 3\n",
    "# Layer 4\n",
    "# Layer 5\n",
    "# Layer 6\n",
    "# Layer 7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Classification: \n",
    "(experiment_1a)-> Logistic Regression\n",
    "(experiment_2a)-> Support Vector Machine\n",
    "(experiment_3a)-> Euclidean Distance Nearest Neighbors\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model with weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
